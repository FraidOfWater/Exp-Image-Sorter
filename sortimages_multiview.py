#pip freeze > requirements.txt && pip uninstall -r requirements.txt -y && del requirements.txt
# are requirements correct?

import os, shutil, json, time, queue, tkinter as tk, ctypes, psutil
from hashlib import md5
from PIL import Image, ImageTk
import threading, multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor
from gui import GUIManager
from navigator import Navigator
import multiprocessing as mp

vipsbin = os.path.join(os.path.dirname(os.path.abspath(__file__)), "vips-dev-8.17", "bin")
os.environ['PATH'] = os.pathsep.join((vipsbin, os.environ['PATH']))
os.add_dll_directory(vipsbin)
import sys
# For Python 3.8+, DLLs must be added via add_dll_directory
if sys.platform == 'win32' and os.path.isdir(vipsbin):
    os.add_dll_directory(vipsbin)

import pyvips



# undo wont add to destw, and undo cant act on destw changes?
# autosave?

# option to disable gridviewer
# menubar stuff into the gui
# # compare new and old vlc implementation # aesthetic tweaks
# purple theme

# overlay in folders which draws over middlepane viewer (resizing), should probably be moved to sorter.py (other overlay code)
# consolidate bindings to one bindhandler?
# end of list behaviour?
# anim debug colors?
# scroll for grid?

# font change to folder buttons
# old random colors back option button
# tooltips
# loading icon for long operations like sorting or training?

#statusbar removal, into title
# load_images_amount?
# settings button to dump the rest into so I can get rid of menubar?

class Imagefile:
    ANIMATION = "ANIMATION"
    IMAGE = "IMAGE"
    VIDEO = "VIDEO"
    def __init__(self, name, path, ext) -> None:
        "An Imagefile object stores data about the image to help us manage it in the program"
        "Normal attributes"
        self.name = name
        self.truncated_filename = None
        self.path = path
        self.dest = ""
        self.thumbnail = None           # Path to the cached thumbnail in data directory
        self.moved = False              # Used to track if img is sorted
        self.ext = ext.lower()
        self.color = None # dest color
        self.embed = None
        self.color_embed = None
        self.predicted_path = None
        self.dimensions = (-2, 0.0)
        self.pos = None
        "Hash"
        self.id = None              # Hash of img name, mod_time and file_size. This is faster to hash than whole file binary stream.
        self.mod_time = None        # Used by sortimages. Used to hash id.
        self.file_size = None       # Used by canvasimage. Buffers if large enough. Used to hash id.
        
        "Animation"
        self.frames = []            # PIL frames for animation with tkinter for imagegrid. Generated by ThumbManager (self.animate) for gif, webp and webm.
        self.index = 0              # Used to control what frame is displayed (for imgagegrid).
        self.delay = 100            #Default delay. Used to fill frametimes if speed can't be extracted from file.
        self.thumb = None           # Store the thumbnail imagetk
        self.frame = None           # Reference to gridframe
        self.destframe = None       # Reference to destframe
        self.gridsquare = None
        self.destsquare = None
        self.change_color_flag = False

        "Prediction"
        self.conf = None
        self.pred = None

    def gen_id(self):
        file_name = self.path.replace('\\', '/').split('/')[-1]
        file_stats = os.stat(self.path)
        self.file_size = file_stats.st_size
        self.mod_time = file_stats.st_mtime
        id = f"{file_name} {file_stats.st_size} {file_stats.st_mtime}"
        self.id = md5(id.encode('utf-8')).hexdigest()
    
    def clear_frames(self):
        self.frames.clear()

    def setdest(self, dest) -> None:
        "Sets imagefile dest and destcolor to desired."
        # if trashed flag, move to "trashed" folder inside our source_dir. during exit, trash these.
        self.moved = False
        self.dest = dest["path"]
        self.dest_color = dest["color"]

    def move(self):
        "Move image from self.path to self.dest and set self.dest = ''. Turn moved flag to True"

        if not self.dest or not os.path.isdir(self.dest): return

        "Pointers"
        name = self.name # in function, better to point  like this or call each time? ###
        old_path = self.path + "" # Perhaps unnecessary, if shutil fails, self.path wont get set to destpath. This is for clarity. This is original path of the file.
        destpath = os.path.join(self.dest, name)

        "Check for conflicts: file with same name already in dest." "Refuse to overwrite anything"
        if os.path.exists(destpath): # path/to/dest/filename
            print(f"File {name[:30]} already exists in destination. No action") # would overwrite with same name otherwise.
            if self.path == destpath: 
                return True # already exists there.
            return False

        try:
            shutil.move(self.path, destpath) # Copy -> Delete. If either fail, do exceptions.
            self.path = destpath
            self.dest = ""
            self.moved = True
            return True
        except Exception as e:
            "Shutil failed: Did delete old fail?"
            if os.path.exists(destpath) and os.path.exists(old_path): # This can only remove files created by shutil due to our early exits checking for anything in the way. Safe.
                os.remove(destpath)
                print(f"File {name[:30]} is in use and is unable to delete. Removing created copy from destination.")
            else:
                print(f"Error moving/deleting: {e} {name[:30]}, This error shouldn't be raised at all. Report/investigate")
            return False

class SortImages:
    THUMB_FORMAT = ".webp"
    supported_formats = {"png", "gif", "jpg", "jpeg", "bmp", "pcx", "tiff", "webp", "psd", "jfif", "mp4", "mkv", "mov", "m4v", "webm", "avif"}

    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, "data")
    trash_dir = os.path.join(script_dir, "Trash")
    os.makedirs(trash_dir, exist_ok=True)
    train_dir = os.path.join(script_dir, "training")
    model_dir = os.path.join(script_dir, "models")
    os.makedirs(model_dir, exist_ok=True)
    model_classes = None
    names_2_path = None

    prefs_path = os.path.join(script_dir, "prefs.json")
    themes_path = os.path.join(script_dir, "themes.json")

    imagelist = [] # Store all Imagefiles
    exclude = []
    assigned = []

    last_sort = (None, False)

    # Flow
    last_call_time = 0
    throttle_delay = 0.19

    # Flags
    autosave = True
    threads = int(os.cpu_count()/2)
    concurrent_frames = 0
    max_concurrent_frames = 2500
    
    def __init__(self) -> None:
        "Sortimages setups the program. It creates imagefiles from the folder given, loads and saves prefs, loads and saves sessions, and starts up the gui and other modules."
        self.jthemes = self.load_themes()
        self.first_run = True
        "Timekeeping and throttling"
        self.timer = Timer()        # Time since creation.

        "Start modules"
        prefs = self.loadprefs()
        if prefs: self.THUMB_FORMAT = prefs.get("THUMB_FORMAT", self.THUMB_FORMAT)
        
        self.gui = GUIManager(self, prefs)
        self.predictions = Predictions(self)
        self.gui.initialize()       # Let GUI initialize fully now with loaded values.
        self.imagegrid = self.gui.imagegrid
        self.navigator = Navigator(self) # Navigator highlights the current selection, main use is to be able to navigate using arrow or wasd keys ### (wasd not implemented)
        self.animate = Animate(self) # Animate module is dedicated for making things animated.
        self.thumbs = ThumbManager(self) # Thumbmanager generates thumbs, frames, truncated names and imagefile attributes, and reloads and unloads resources when needed.
        
        self.gui.after(3000, self.update_info)
        self.val_thumb_cache(self.data_dir)
        self.gui.mainloop()
    
    def val_thumb_cache(self, path):
        "Setups cache folder for thumbnails. If folder doesn't exist, it is created. If the first picture in it is not the expected size, the folder is emptied."

        "Data folder doesn't exists: creates it"
        if not (os.path.exists(path) and os.path.isdir(path)):
            os.mkdir(path)
            return
        
        testable = None
        with os.scandir(path) as entries:
            for entry in entries:
                if entry.is_file() and entry.name.endswith(self.THUMB_FORMAT):
                    testable = entry
                    break
        
        if not testable:
            print(f"Data folder is empty")
            return
        

        with Image.open(testable.path) as im:
            width, height = im.size
        if max(width, height) != self.gui.thumbnailsize:
            try:
                print("Removing data folder, thumbnailsize changed")
                shutil.rmtree(path)
                os.mkdir(path)
                print("Re-created data folder.")
            except Exception as e:
                print(f"Couldn't delete/create data folder: {e}")

    def loadprefs(self):
        "Loads prefs.json. Needs self.gui to be created. This edits self.gui attributes."
        try:
            with open(self.prefs_path, "r") as prefsfile:
                jdata = prefsfile.read()
                jprefs = json.loads(jdata)
                return jprefs
        except Exception as e:
            print(f"Error loading prefs.json: {e}")
            return None
        
    def saveprefs(self, gui):
        "Saves all customizable stuff to prefs.json."
        if gui.middlepane_frame.winfo_width() == 1: # Do not try to save invalid value
            pass
        else:
            gui.middlepane_width = gui.middlepane_frame.winfo_width()

        sdp = gui.source_entry_field.get() if os.path.exists(gui.source_entry_field.get()) else ""
        ddp = gui.destination_entry_field.get() if os.path.exists(gui.destination_entry_field.get()) else ""

        temp = gui.squares_per_page_intvar.get()
        if temp == "":
            temp = 1
        save = {
            "paths": {
                "source": sdp,
                "destination": ddp,
                "lastsession": gui.lastsession,
                "exclude": self.exclude,
                "categories": self.gui.categories,
                "excludes": self.gui.excludes,
                "model": self.gui.model_path
            },
            "user": {
                "thumbnailsize": gui.thumbnailsize,
                "prediction_thumbsize": gui.prediction_thumbsize,
                "hotkeys": gui.hotkeys,
                "force_scrollbar": gui.force_scrollbar,
                "auto_load": gui.auto_load,
                "do_anim_loading_colors": gui.do_anim_loading_colors,
                "show_statusbar": gui.show_statusbar.get(),
                "show_ram": gui.show_ram.get(),
                "show_advanced": gui.show_advanced.get(),
            },
            "technical": {
                "quick_preview_filter": gui.filter_mode,
                "threads": self.threads,
                "max_concurrent_frames": self.max_concurrent_frames,
                "autosave_session":self.autosave,
                "THUMB_FORMAT": self.THUMB_FORMAT
            },
            
            "qui": {
                "squares_per_page": gui.squares_per_page_intvar.get(),
                "display_order": gui.display_order.get(),
                "show_next": gui.show_next.get(),
                "dock_view": gui.dock_view.get(),
                "dock_side": gui.dock_side.get(),
                "theme": gui.theme.get(),
                "volume": gui.volume,
            },
            "window_settings": {
                "main_geometry": gui.winfo_geometry(),
                "viewer_geometry": gui.viewer_geometry,
                "destpane_geometry":gui.destpane_geometry,
                "leftpane_width": max(gui.leftui.winfo_width(), 50),
                "middlepane_width": gui.middlepane_width if int(gui.winfo_geometry().split("x", 1)[0])-gui.middlepane_width-gui.leftui.winfo_width() > gui.thumbnailsize//2 else gui.middlepane_width-gui.thumbnailsize//2,
                "images_sorted":gui.images_sorted.get(),
            }
        }
        save["viewer"] = gui.viewer_prefs

        "Save to prefs.json"
        try:
            with open(self.prefs_path, "w+") as json_file:
                json.dump(save, json_file, indent=4)
        except Exception as e:
            print(("Failed to save prefs:", e))

        "Save session"
        try:
            if self.autosave:
                self.savesession(asksavelocation=False)
        except Exception as e:
            print(("Failed to save session:", e))
    
    def savesession(self, asksavelocation):
        "Saves assigned without having to move them."
        "If there is nothing to save"
        if not self.assigned: return

        if asksavelocation:
            from tkinter import filedialog as tkFileDialog
            custom_session_name = f"{os.path.basename(self.sdp)}-{os.path.basename(self.ddp)}.json" 
            filet=[("Javascript Object Notation","*.json")]
            savelocation=tkFileDialog.asksaveasfilename(confirmoverwrite=True,defaultextension=filet,filetypes=filet,
                                                        initialdir=os.getcwd(),initialfile=custom_session_name)
        else:
            savelocation = "last_session.json"

        if not savelocation: return
        seen = {}
        assigned = []
        for x in self.assigned:
            seen[x.dest] = x.color
            assigned.append((x.path, x.dest))
        self.moved = []
        save = {"destination": self.ddp, "source": self.sdp, "colors": seen, "assigned": assigned, "moved": self.moved}

        with open(os.path.join(self.script_dir, savelocation), "w+") as json_file:
            json.dump(save, json_file, indent=4)    

    def loadsession(self):
        gui = self.gui
        "If there is no last session, early exit"
        if not (os.path.exists(gui.lastsession) and os.path.isfile(gui.lastsession)):
            print("No Last Session!")
            return
        
        with open(gui.lastsession, "r") as json_file:
            sdata = json_file.read()
            savedata = json.loads(sdata)

        self.sdp = savedata['source']
        self.ddp = savedata['destination']

        gui.guisetup()

        print("")
        print(f'Using session:  "{os.path.basename(gui.lastsession)}"')
        print(f'Source:   "{self.sdp}"')
        print(f'Target:   "{self.ddp}"')

        temp = []
        for x in savedata["assigned"]:
            path, dest = x
            name = os.path.basename(path)
            parts = name.rsplit(".", 1)
            if len(parts) == 2:
                n, ext = parts
                ext = ext.lower()
            else:
                n = parts[0]
                ext = ""
            obj = Imagefile(name, path, ext.lower())
            obj.dest = dest
            obj.color = savedata["colors"][dest]
            temp.append(obj)
            
        self.assigned = temp

        self.validate()


    def load_themes(self):
        try:
            with open(self.themes_path, "r") as themesfile:
                jdata = themesfile.read()
                jthemes = json.loads(jdata)
                return jthemes["themes"]
        except Exception as e:
            print("Error loading themes:", e)
            return None
    
    def moveall(self):
        self.timer.start()
        gui = self.gui
        imagegrid = gui.imagegrid
        temp = self.assigned.copy()

        successfull = []
        for obj in temp:
            success = obj.move()
            if success: # If move was successfull
                self.assigned.remove(obj)
                #imagegrid.moved.append(x)
                gui.images_left_stats_strvar.set(
                    f"Left: {len(self.assigned)}/{len(self.all_objs)-len(self.assigned)}/{len(self.all_objs)}")
                gui.images_sorted.set(gui.images_sorted.get()+1)
                gui.images_sorted_strvar.set(f"Sorted: {gui.images_sorted.get()}")
                gui.winfo_toplevel().title(f"EXP: {gui.images_sorted_strvar.get()}")

                successfull.append(obj)
        
        """if self.gui.current_view.get() == "Assigned":
            imagegrid.remove_squares(successfull, unload=True)"""

        print(self.timer.stop())

    def setDestination(self, dest, caller=None):
        if caller:
            f = self.gui.focus_get()
            if hasattr(f, "widgetName") and f.widgetName == "entry": return
            viewer_open = self.gui.Image_frame or self.gui.second_window_viewer
            search_open = False if not viewer_open else viewer_open.app2.search_active

            if caller == "autosort" and search_open: return
            if caller == "sorter" or caller == "autosort": # Pressing enter while search is active or we are in prediction view and we pressed enter key to auto assign.
                print("SORTER CALL")
                pass
            elif caller.type == tk.EventType.ButtonPress: # clicking on a button
                pass
            elif isinstance(caller.widget, tk.Entry): # writing in an entry box.
                return
            elif caller.type == tk.EventType.KeyPress: # pressing a hotkey
                if caller.keysym == "Delete":
                    pass
                elif search_open: 
                    return

        # if viewer open and search box active, ignore all keypresses
        # if viewer open and minimized, ignore all keypresses except "Delete"
        "Ignored"
        if True:
            "Ignore calls if they are spammed"
            current_time = time.perf_counter()
            if current_time - self.last_call_time < 0.1: return
            else: self.last_call_time = current_time

        gui = self.gui
        imagegrid = gui.imagegrid
        "Find all marked images"

        
        selection = None
        current_view = gui.current_view.get()
        if imagegrid.current_selection is not None and self.navigator.window_focused == "GRID":
            index = self.imagegrid.current_selection
            if len(imagegrid.image_items) > index:
                selection = imagegrid.image_items[index] # selection

        igrid_marked = gui.imagegrid.selected.copy()
        
        dgrid_marked = []
        d_selection = None

        if hasattr(self.gui.folder_explorer, "destw") and self.gui.folder_explorer.destw != None and self.gui.folder_explorer.destw.winfo_exists():
            if gui.folder_explorer.destw.current_selection is not None and self.navigator.window_focused == "DEST":
                index = gui.folder_explorer.destw.current_selection
                if len(gui.folder_explorer.destw.image_items) > index:
                    d_selection = gui.folder_explorer.destw.image_items[index] # selection
            dgrid_marked = gui.folder_explorer.destw.selected.copy()
            gui.folder_explorer.destw.selected.clear()
        
        if selection and d_selection:
            selection = None; d_selection = None
            print("both active")

        if not dgrid_marked and not igrid_marked:
            if selection: igrid_marked.append(selection)
            if d_selection: dgrid_marked.append(d_selection)

        gui.imagegrid.selected.clear()

        # not parsing through selections of destw yet.
        # dont know if mvoed fill update assigned list...
        
        remove = []
        add = []
        for entry in igrid_marked: # from main to destw
            obj = entry.file
            obj.setdest(dest)
            obj.color = dest['color']
            if hasattr(self.gui.folder_explorer, "destw") and self.gui.folder_explorer.destw != None and self.gui.folder_explorer.destw.winfo_exists():
                for i in range(0, len(self.gui.folder_explorer.destw.image_items)):
                    if obj == self.gui.folder_explorer.destw.image_items[i].file: # already there, remove
                        remove.append(obj)
                        break
                if self.gui.folder_explorer.destw.destination == dest["path"]: # if its destined there, add
                    add.append(obj)
                if remove: 
                    self.gui.folder_explorer.destw.remove(remove)
                if add: 
                    self.gui.folder_explorer.destw.insert_first(add)
        
        objs = [entry.file for entry in igrid_marked] # igrid handles itself here.
        if objs:
            if current_view == "Unassigned": # assigned list is not in order of added!
                index = imagegrid.remove(objs)
                self.assigned.extend(objs)
                pass
            else:
                imagegrid.remove(objs, unload=False)
                imagegrid.insert_first(objs)
                for obj in objs:
                    self.assigned.remove(obj)
                self.assigned.extend(objs)
        
        for entry in dgrid_marked:
            obj = entry.file
            obj.setdest(dest)
            obj.color = dest['color']
            for i in range(0, len(self.gui.folder_explorer.destw.image_items)):
                if obj == self.gui.folder_explorer.destw.image_items[i].file: # already there, remove
                    remove.append(obj)
                    break
            if self.gui.folder_explorer.destw.destination == dest["path"]: # if its destined there, add
                add.append(obj)
            if remove: 
                self.gui.folder_explorer.destw.remove(remove)
            if add: 
                self.gui.folder_explorer.destw.insert_first(add)
        
        objs = [entry.file for entry in dgrid_marked] # igrid handles itself here.
        if objs:
            if current_view == "Unassigned": # assigned list is not in order of added!
                pass
            else:
                remove = []
                add = []
                for obj in objs:
                    for i in range(0, len(imagegrid.image_items)):
                        if obj == imagegrid.image_items[i].file: # already there, remove
                            remove.append(obj)
                            self.assigned.remove(obj)
                            break
                    add.append(obj)

                imagegrid.remove(remove)
                imagegrid.insert_first(add)
                self.assigned.extend(add)
                
        # Load more
        if gui.auto_load and (current_view == "Unassigned"): self.load_more()

        if caller and hasattr(caller, "widget") and "toplevel" in caller.widget._w:
            if self.gui.folder_explorer.destw.current_selection is not None and self.gui.folder_explorer.destw.current_selection < len(self.gui.folder_explorer.destw.image_items):
                selected_entry = self.gui.folder_explorer.destw.image_items[self.gui.folder_explorer.destw.current_selection]
                self.gui.folder_explorer.destw.make_selection(selected_entry)
                if self.gui.show_next.get():
                    self.gui.displayimage(selected_entry.file)
        else:
            if imagegrid.current_selection is not None and imagegrid.current_selection < len(imagegrid.image_items):
                selected_entry = imagegrid.image_items[imagegrid.current_selection]
                imagegrid.make_selection(selected_entry)
                if self.gui.show_next.get():
                    self.gui.displayimage(selected_entry.file)

        # Update stats
        gui.images_left_stats_strvar.set(
            f"Left: {len(self.assigned)}/{len(self.all_objs)-len(self.assigned)}/{len(self.all_objs)}")
    
    def validate(self, btn=None): # new session
        if btn and self.first_run: 
            return
        else:
            self.first_run = False
        gui = self.gui
        timer = self.timer; timer.start()
        self.sdp = gui.source_entry_field.get()
        self.ddp = gui.destination_entry_field.get()
        samepath = (self.sdp == self.ddp)

        if os.path.isdir(self.sdp):
            pass
        else:
            gui.source_entry_field.delete(0, tk.END)
            gui.source_entry_field.insert(0, "ERROR INVALID PATH")
            gui.source_entry_field.xview_moveto(1.0)
            
        if os.path.isdir(self.ddp):
            pass
        else:
            gui.destination_entry_field.delete(0, tk.END)
            gui.destination_entry_field.insert(0, "ERROR INVALID PATH")
            gui.destination_entry_field.xview_moveto(1.0)
        
        if os.path.isdir(self.sdp) and os.path.isdir(self.ddp):
            if not hasattr(self.gui, "folder_explorer"):
                gui.guisetup()
            #if gui.imagegrid.gridsquarelist:
            #    gui.imagegrid.clear_all()
            if gui.Image_frame != None:
                gui.Image_frame.set_image(None)
            if gui.second_window_viewer != None:
                gui.second_window_viewer.set_image(None)
            gui.folder_explorer.set_view(self.ddp)
            gui.buttons = gui.folder_explorer.buttons.copy()
            
            print("")
            print(f'Source:   "{self.sdp}"')
            print(f'Target:   "{self.ddp}"')
            
            self.imagelist = self.walk(self.sdp, samepath)
            gui.images_left_stats_strvar.set(
            f"Left: {len(self.assigned)}/{len(self.imagelist)-len(self.assigned)}/{len(self.imagelist)}")

            self.gui.imagegrid.clear_canvas(unload=True)
            self.sort_imagelist()
            timer.start()

        self.gui.update_idletasks()
        #self.navigator.first()

    def load_more(self):
        count_in_grid = len(self.gui.imagegrid.image_items)
        amount = self.gui.squares_per_page_intvar.get()
        to_load = amount - count_in_grid
        left = len(self.imagelist)
        items = min(to_load, left)
        if items <= 0: return
        load = []
        a = len(self.imagelist)
        for i in range(a - 1, a-1-items, -1):
            load.append(self.imagelist.pop(i))

        self.gui.imagegrid.add(load)

    def walk(self, src, samepath):
        imagelist = []
        for root, dirs, files in os.walk(src, topdown=True):
            dirs[:] = [d for d in dirs if d not in self.exclude]
            for name in files:
                parts = name.rsplit(".", 1)
                if len(parts) == 2:
                    n, ext = parts
                    ext = ext.lower()
                else:
                    n = parts[0]
                    ext = ""
                if ext in self.supported_formats:imagelist.append(Imagefile(name, os.path.join(root, name), ext))
            if samepath: break
        if self.assigned:
            identity_check = set([x.path for x in self.assigned])
            return [x for x in imagelist if x.path not in identity_check]
        return imagelist

    def sort_imagelist(self):
        # remove from imagelist, but add back from image_items
        from operator import attrgetter
        from natsort import natsorted
        from PIL import Image
        if self.first_run: return
        gui = self.gui

        def after_tasks():
            self.all_objs = self.imagelist.copy()
            if self.gui.current_view.get() == "Unassigned":
                self.load_more()
        if self.gui.current_view.get() != "Unassigned": return
        MODE = gui.display_order.get().lower()
        grid_objects = [entry.file for entry in gui.imagegrid.image_items]
        self.imagelist.extend(reversed(grid_objects))
        gui.imagegrid.clear_canvas()
        if self.last_sort[0] == MODE.lower():
            self.last_sort = (self.last_sort[0], not self.last_sort[1])
        else:
            self.last_sort = (MODE.lower(), False)

        if gui.prediction.get():
            def run():
                # reorder by confidence.
                CONF_THRESHOLD = 0.4            
                no_pred = []
                predictable = []
                for x in self.imagelist:
                    if x.pred:
                        predictable.append(x)
                    else:
                        no_pred.append(x)

                # group together with same predicted label.
                classes = {}
                for x in predictable:
                    if classes.get(x.pred, None) == None:
                        classes[x.pred] = []
                    classes[x.pred].append(x)

                # distinguish using colors
                for key, c in classes.items():
                    c[:] = [x for x in c if x.conf >= CONF_THRESHOLD]
                    if len(c) < 2:
                        continue
                    
                    if MODE.lower() == "filename":
                        classes[key] = natsorted(c, key=attrgetter("name"), reverse=True if self.last_sort[1] == False else False)
                    elif MODE.lower() == "type":
                        c.sort(key=lambda x: x.ext.lower(), reverse=False if self.last_sort[1] == False else True)
                    elif MODE.lower() == "date":
                        for obj in c:
                            obj.mod_time = os.path.getmtime(obj.path)
                        c.sort(key=attrgetter("mod_time"), reverse=False if self.last_sort[1] == False else True)
                    elif MODE == "size":
                        for obj in c:
                            file_stats = os.stat(obj.path)
                            obj.file_size = file_stats.st_size
                        c.sort(key=attrgetter("file_size"), reverse=False if self.last_sort[1] == False else True)
                    elif MODE == "dimensions":
                        try:
                            from imageio import get_reader
                        except Exception as e:
                            get_reader = None
                            print(f"[Warning] imageio.get_reader unavailable: {e}")
                        for obj in c:
                            if obj.dimensions == (-2, 0.0):
                                if obj.ext in ("mp4", "webm"):
                                    try:
                                        reader = None
                                        reader = get_reader(obj.path)
                                        pil_img = Image.fromarray(reader.get_data(0))
                                        w, h = pil_img.size
                                        ratio = w/h # ratio 
                                        if w == h: orientation = 0.0
                                        elif w < h: orientation = -1.0
                                        else: orientation = 1.0
                                        obj.dimensions = (orientation, ratio)
                                    except Exception as e:
                                        print(f"Couldn't read: {obj.name} : Error: {e}")
                                    finally: 
                                        if reader: reader.close()
                                else:
                                    with Image.open(obj.path) as pil_img:
                                        w, h = pil_img.size
                                        ratio = w/h # ratio
                                        if w == h: orientation = 0.0
                                        elif w < h: orientation = -1.0
                                        else: orientation = 1.0
                                        obj.dimensions = (orientation, ratio)
                                        
                        c.sort(key=attrgetter("dimensions"), reverse=False if self.last_sort[1] == False else True)

                    elif MODE.lower() == "nearest":
                        self.reorder_as_nearest(c, reverse=self.last_sort[1])
                    elif MODE.lower() == "confidence":
                        c.sort(key=lambda x: x.conf, reverse=False if self.last_sort[1] == False else True) 
                classes = sorted(list(classes.values()), key=lambda x: len(x), reverse=False if self.last_sort[1] == False else True) # sorted by class and conf

                predictable = []
                for x in classes:
                    predictable.extend(x)

                def helper():
                    self.imagelist = predictable + no_pred
                    after_tasks()
                gui.after(1, helper)
            def helper():
                self.reorder_as_nearest(self.imagelist, reverse=self.last_sort[1])
                gui.after(1, run)
            if MODE == "nearest":
                a = threading.Thread(target=helper, daemon=True)
            else:
                a = threading.Thread(target=run, daemon=True)
            a.start()
            return        
        elif MODE == "filename":
            self.imagelist = natsorted(self.imagelist, key=attrgetter("name"), reverse=True if self.last_sort[1] == False else False)
        elif MODE == "type":
            self.imagelist.sort(key=lambda x: x.ext.lower(), reverse=False if self.last_sort[1] == False else True)
        elif MODE == "date":
            for obj in self.imagelist:
                obj.mod_time = os.path.getmtime(obj.path)
            self.imagelist.sort(key=attrgetter("mod_time"), reverse=False if self.last_sort[1] == False else True)
        elif MODE == "size":
            for obj in self.imagelist:
                file_stats = os.stat(obj.path)
                obj.file_size = file_stats.st_size
            self.imagelist.sort(key=attrgetter("file_size"), reverse=False if self.last_sort[1] == False else True)
        elif MODE == "dimensions":
            try:
                from imageio import get_reader
            except Exception as e:
                get_reader = None
                print(f"[Warning] imageio.get_reader unavailable: {e}")
            for obj in self.imagelist:
                if obj.dimensions == (-2, 0.0):
                    if obj.ext in ("mp4", "webm", "mkv", "m4v", "mov"):
                        try:
                            reader = None
                            reader = get_reader(obj.path)
                            pil_img = Image.fromarray(reader.get_data(0))
                            w, h = pil_img.size
                            ratio = w/h # ratio 
                            if w == h: orientation = 0.0
                            elif w < h: orientation = -1.0
                            else: orientation = 1.0
                            obj.dimensions = (orientation, ratio)
                        except Exception as e:
                            print(f"Couldn't read: {obj.name} : Error: {e}")
                        finally: 
                            if reader: reader.close()
                    else:
                        with Image.open(obj.path) as pil_img:
                            w, h = pil_img.size
                            ratio = w/h # ratio
                            if w == h: orientation = 0.0
                            elif w < h: orientation = -1.0
                            else: orientation = 1.0
                            obj.dimensions = (orientation, ratio)

            self.imagelist.sort(key=attrgetter("dimensions"), reverse=True if self.last_sort[1] == False else False)
        elif MODE == "nearest": # threaded gen
            def helper1():
                self.reorder_as_nearest(self.imagelist, reverse=self.last_sort[1])
                gui.after(1, after_tasks)
            a = threading.Thread(target=helper1, daemon=True) # dont freeze the program do it threaded
            a.start()
            print("Started thread to sort by Nearest Neighbour. Please wait.")
            return

        after_tasks()
        #main_thread()
        
    def reorder_as_nearest(self, imagefiles, optimization=False, reverse=False):
        import numpy as np
        import concurrent.futures
        import time
        TARGET_SIZE = (224, 224)
        BATCH_SIZE = 64
        #SAVE_PATH = r"C:\Users\4f736\Downloads\sort\results"
        PRESET = 1 # 2
        #os.makedirs(SAVE_PATH, exist_ok=True)
        start = time.perf_counter()
        TARGET_SIZE = 224  # used by pyvips.thumbnail()

        def load_images_threadsafe(imagefiles):
            """Load, resize, and pad images with black bars to TARGET_SIZE using PyVips (multi-threaded)."""
            images = [None] * len(imagefiles)
            objs = [None] * len(imagefiles)

            with concurrent.futures.ThreadPoolExecutor(
                max_workers=max(1, self.threads - 1), thread_name_prefix="mobilenet_thumbs"
            ) as executor:
                futures = {executor.submit(self.thumbs.gen_thumb, obj, size=TARGET_SIZE, cache_dir=None, user="mobilenet", mode="letterbox"): i
                        for i, obj in enumerate(imagefiles)}

                for f in concurrent.futures.as_completed(futures):
                    i = futures[f]
                    result = f.result()
                    if isinstance(result, tuple):
                        img, obj = result
                        if img is not None and obj is not None:
                            images[i] = img
                            objs[i] = obj

            # Filter out failed loads while preserving order
            valid = [(img, obj) for img, obj in zip(images, objs) if img is not None and obj is not None]
            if not valid:
                return np.empty((0, TARGET_SIZE, TARGET_SIZE, 3), dtype=np.uint8), []
            
            images, objs = zip(*valid)
            return np.stack(images), list(objs)

        def letterbox(img, size):
            w, h = img.size
            new_im = Image.new("RGB", (size, size), (114, 114, 114))
            left = (size - w) // 2
            top = (size - h) // 2
            new_im.paste(img, (left, top))
            return new_im
        def threaded_letterboxing(images):
            thumbs = [None] * len(images)

            with concurrent.futures.ThreadPoolExecutor(
                max_workers=max(1, self.threads - 1), thread_name_prefix="mobilenet_thumbs"
            ) as executor:
                futures = {executor.submit(letterbox, img, size=TARGET_SIZE): i for i, img in enumerate(images)}
                for f in concurrent.futures.as_completed(futures):
                    i = futures[f]
                    thumbs[i] = f.result()

            return thumbs

        def get_mobilenet_embeddings(images):
            """Compute MobileNet feature embeddings in batches."""
            import torch
            import torchvision.transforms as T
            import torchvision.models as models
            from torchvision.models import MobileNet_V2_Weights
            device = "cuda" if torch.cuda.is_available() else "cpu"
            #model = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).to(device)
            model = models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1).to(device)
            model.eval()

            preprocess = T.Compose([
                T.Resize(224),
                T.CenterCrop(224),
                T.ToTensor(),
                T.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225]),
            ])

            all_emb = []
            with torch.no_grad():
                for i in range(0, len(images), BATCH_SIZE):
                    print("Embed:", i+BATCH_SIZE)
                    batch = images[i:i+BATCH_SIZE]
                    batch_tensor = torch.stack([preprocess(Image.fromarray(img)) for img in batch]).to(device)
                    feats = model.features(batch_tensor)
                    pooled = torch.nn.functional.adaptive_avg_pool2d(feats, (1, 1)).view(len(batch), -1)
                    all_emb.append(pooled.cpu().numpy())

            embeddings = np.concatenate(all_emb, axis=0)
            embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)
            return embeddings

        def get_dominant_center_color(img, crop_ratio=0.6, similarity_threshold=32):
            try:
                img_f = img.astype(np.float32)
                h, w, _ = img_f.shape

                # --- Center crop ---
                ch, cw = int(h * crop_ratio), int(w * crop_ratio)
                top, left = (h - ch) // 2, (w - cw) // 2
                center_crop = img_f[top:top+ch, left:left+cw].reshape(-1, 3)

                # --- Background crop ---
                mask = np.ones((h, w), dtype=bool)
                mask[top:top+ch, left:left+cw] = False
                background_crop = img_f[mask].reshape(-1, 3)

                if len(background_crop) == 0:
                    return np.median(center_crop, axis=0)

                # --- Compute distances from background pixels ---
                # Using simple RGB Euclidean distance
                bg_median = np.median(background_crop, axis=0)
                dists = np.linalg.norm(center_crop - bg_median[None, :], axis=1)

                # Keep pixels that are sufficiently different from background
                fg_pixels = center_crop[dists > similarity_threshold]

                if len(fg_pixels) == 0:
                    # fallback: use center crop median
                    fg_pixels = center_crop

                dominant_color = np.median(fg_pixels, axis=0)
                return np.clip(dominant_color, 0, 255)

            except Exception:
                return np.median(img_f.reshape(-1, 3), axis=0)

        def get_median_center_color(img, crop_ratio=0.5):
            """Compute median center color in RGB for each image."""
            try:
                h, w, _ = img.shape
                ch, cw = int(h * crop_ratio), int(w * crop_ratio)
                top = (h - ch) // 2
                left = (w - cw) // 2
                crop = img[top:top+ch, left:left+cw]
                return np.median(crop.reshape(-1, 3), axis=0)
            except Exception:
                return np.zeros(3)
        
        def get_order_tsp(combined, k=20):
            """Use k-nearest neighbor TSP-like heuristic for smoother ordering."""
            import faiss
            index = faiss.IndexFlatL2(combined.shape[1])
            index.add(combined.astype(np.float32))
            D, I = index.search(combined.astype(np.float32), k)

            visited = np.zeros(len(combined), dtype=bool)
            order = [0]
            visited[0] = True

            for _ in range(1, len(combined)):
                last = order[-1]
                found = False

                # Try nearest neighbors first
                for neighbor in I[last]:
                    if not visited[neighbor]:
                        order.append(neighbor)
                        visited[neighbor] = True
                        found = True
                        break

                # Fallback: find globally nearest unvisited
                if not found:
                    unvisited = np.where(~visited)[0]
                    if len(unvisited) == 0:
                        break
                    # use FAISS to find closest among remaining
                    D2, I2 = index.search(combined[last:last+1].astype(np.float32), len(combined))
                    for neighbor in I2[0]:
                        if not visited[neighbor]:
                            order.append(neighbor)
                            visited[neighbor] = True
                            break
            return order
        
        if optimization:
            images, objs_to_encode = optimization
            images = threaded_letterboxing(images)
            if not images: images, objs_to_encode = np.empty((0, TARGET_SIZE, TARGET_SIZE, 3), dtype=np.uint8), []
            else:
                images = np.stack(images)
        else:
            test = sorted(imagefiles, key=lambda x: x.name)
            images, objs_to_encode = load_images_threadsafe(test)
        
        alpha = 0.7 if PRESET == 1 else 0.4

        with concurrent.futures.ThreadPoolExecutor(max_workers=max(1, self.threads - 1), thread_name_prefix="mobilenet-colors") as executor:
            func = get_dominant_center_color if PRESET == 1 else get_median_center_color
            futures = {executor.submit(func, img): i for i, img in enumerate(images)}
            dominant_colors = [None] * len(images)

            for f in concurrent.futures.as_completed(futures):
                i = futures[f]
                dominant_colors[i] = f.result()

            color_emb_new = np.array(dominant_colors, dtype=np.float32)

            for obj, col in zip(objs_to_encode, color_emb_new):
                obj.color_embed = np.asarray(col, dtype=np.float32)

            if len(objs_to_encode) > 0:
                embeddings_new = get_mobilenet_embeddings(images)
                for obj, emb in zip(objs_to_encode, embeddings_new):
                    obj.embed = np.asarray(emb, dtype=np.float32)


        if optimization: 
            print(time.perf_counter()-start)
            
            return
        objs_with_both = [
            obj for obj in test
            if getattr(obj, "embed", None) is not None and getattr(obj, "color_embed", None) is not None
        ]
        if len(objs_with_both) == 0:
            print("No objects with both embed and color_embed â€” aborting.")
            return

        # 5) Stack arrays in the same order
        all_emb = np.vstack([np.asarray(obj.embed, dtype=np.float32).reshape(1, -1) for obj in objs_with_both])
        color_emb = np.vstack([np.asarray(obj.color_embed, dtype=np.float32).reshape(1, -1) for obj in objs_with_both])

        # 6) normalize color embeddings safely
        norms = np.linalg.norm(color_emb, axis=1, keepdims=True)
        norms[norms == 0] = 1e-8
        color_emb /= norms

        combined = np.concatenate([alpha * all_emb, (1 - alpha) * color_emb], axis=1)
        order = get_order_tsp(combined)

        ordered_objs = [objs_with_both[idx] for idx in reversed(order)]

        remaining = [o for o in imagefiles if o not in objs_with_both]
        imagefiles[:] = ordered_objs + remaining
        if reverse:
            imagefiles.reverse()

        print(time.perf_counter()-start)

    def update_info(self, old=None):
        def get_memory_usage():
            # Get the current process
            process = psutil.Process()

            # Get memory info
            memory_info = process.memory_info()

            # Return the RSS (Resident Set Size) in bytes
            return (memory_info.rss)
        
        if self.gui.show_ram.get():
            self.gui.current_ram_strvar.set(f"RAM: {get_memory_usage() / (1024 ** 2):.2f} MB")

        "Anim: displayedlist with frames/displayedlist with framecount/(queue)"
        temp = [x for x in self.imagegrid.image_items if x.file.frames]
        self.gui.animation_stats_var.set(f"Anim: {len(self.animate.running)}/{len(temp)}")

        "Frames: frames + frames_dest / max"
        temp = [x.file.frames for x in self.imagegrid.image_items if x.file.frames]
        c = 0
        for x in temp:
            c += len(x)
        self.gui.resource_limiter_var.set(f"{c}/{self.max_concurrent_frames}")

        self.concurrent_frames = c
        with self.thumbs._cf_cond:
            self.thumbs._cf_cond.notify_all()

        self.gui.after(333, self.update_info)

class ThumbManager:
    class CachedTruncator:
        def __init__(self, thumbmanager):
            self.thumbs = thumbmanager
            self.gui = thumbmanager.gui
            self.prefix_width_cache = {}
            self.char_width_cache = {}
            self.measure_calls = 0
            self.ellipsis = "...."
            self.padding = 0
            self.ellipsis_width = self.gui.smallfont.measure(self.ellipsis)

        def truncate(self, filename):
            parts = filename.rsplit(".", 1)
            
            if len(parts) == 2:
                base, ext = parts
                ext_w = self.prefix_width_cache.get(ext, False)
                if ext_w == False:
                    ext_w = self.gui.smallfont.measure(ext)
                    self.prefix_width_cache[ext] = ext_w
                    self.measure_calls += 1
            else:
                base = filename
                ext = ""
                ext_w = 0

            base_chars_w = []
            base_w = 0
            for char in base:
                char_w = self.char_width_cache.get(char, False)
                if char_w == False:
                    char_w = self.gui.smallfont.measure(char)
                    self.char_width_cache[char] = char_w
                    self.measure_calls += 1

                base_w += char_w
                base_chars_w.append(base_w)
            
            if base_w + ext_w <= self.gui.thumbnailsize - self.padding:
                return filename
            
            available = self.gui.thumbnailsize - self.padding - self.ellipsis_width - ext_w
            
            # Binary search using precomputed widths
            lo, hi = 0, len(base)
            while lo < hi:
                if self.thumbs.stop_event.is_set(): return
                mid = (lo + hi + 1) // 2
                if base_chars_w[mid - 1] <= available:
                    lo = mid
                else:
                    hi = mid - 1

            return f"{base[:lo]}{self.ellipsis}{ext}"
    class DaemonThreadPoolExecutor(ThreadPoolExecutor):
        """ThreadPoolExecutor that sets all worker threads as daemon threads."""
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self._set_daemon_threads(kwargs["thread_name_prefix"])

        def _set_daemon_threads(self, name):
            """
            Replace all non-daemon threads in the executor with daemon threads.
            Called after pool creation. Compatible with Python 3.9â€“3.13.
            """
            old_threads = list(self._threads)
            self._threads.clear()
            for i in range(len(old_threads), self._max_workers):
                t = threading.Thread(target=self._worker_entry, name=f"{name}_{i+1}", daemon=True)
                t.start()
                self._threads.add(t)

        def _worker_entry(self):
            """Our wrapper for the internal work queue processing loop."""
            while True:
                try:
                    work_item = self._work_queue.get(block=True)
                    if work_item is None:
                        break
                    work_item.run()
                    del work_item
                except Exception:
                    import traceback
                    traceback.print_exc()
    thumb_ext = {"png", "jpg", "jpeg", "bmp", "pcx", "tiff", "psd", "jfif", "gif", "webp", "avif"}
    anim_ext = {"gif", "webp", "webm", "mp4", "mkv", "m4v", "mov"}
    video_ext = {"webm", "mp4", "mkv", "m4v", "mov"}
    thumb_pool = None
    frame_pool = None
    def __init__(self, fileManager):
        self.fileManager = fileManager
        self.gui = fileManager.gui
        self.threads = fileManager.threads
        self.data_dir = fileManager.data_dir

        self.thumb_after_id = None
        self.frame_after_id = None
        
        # Queues
        self.thumb_queue = queue.Queue()
        self.frame_queue = queue.Queue()

        # Worker threads
        self.thumb_worker = None
        self.frame_worker = None
        self.stop_event = threading.Event()
        self.worker_ready = threading.Event()
        self._cf_lock = threading.Lock()
        self._cf_cond = threading.Condition(self._cf_lock)
        self._left_lock = threading.Lock()
        self.left = 0
        self.left_f = 0

        self.truncator = ThumbManager.CachedTruncator(self)

        # Thread pool sizes
        self.thumb_workers = min(5, fileManager.threads)  # parallel thumbs
        self.frame_workers = min(3, fileManager.threads)  # parallel frames

    def start_background_worker(self):
        if self.stop_event.is_set():
            self.stop_event.clear()

        # recreate executors if missing
        if not getattr(self, "thumb_pool", None):
            self.thumb_pool = ThumbManager.DaemonThreadPoolExecutor(thread_name_prefix="(Pool) T_thread", max_workers=self.thumb_workers)
        if not getattr(self, "frame_pool", None):
            self.frame_pool = ThumbManager.DaemonThreadPoolExecutor(thread_name_prefix="(Pool) F_thread", max_workers=self.frame_workers)

        # start worker threads only if dead
        if not getattr(self, "_thumb_worker_running", False):
            self._thumb_worker_running = True
            self.thumb_after_id = self.gui.after(100, self._thumb_worker)

        # start worker threads only if dead
        if not getattr(self, "_frame_worker_running", False):
            self._frame_worker_running = True
            self.frame_after_id = self.gui.after(100, self._frame_worker)

    def stop_background_worker(self):
        """Tell workers to stop, but never block the main thread."""
        self.stop_event.set()
        if self.thumb_after_id:
            self.gui.after_cancel(self.thumb_after_id)
        if self.frame_after_id:
            self.gui.after_cancel(self.frame_after_id)

        # cancel new jobs

        for pool in (self.thumb_pool, self.frame_pool):
            if pool:
                pool.shutdown(wait=False, cancel_futures=True)

        self.thumb_pool = None
        self.frame_pool = None
        # clear queues so get() unblocks
        for q in (self.thumb_queue, self.frame_queue):
                with q.mutex:
                    q.queue.clear()
                    
        # schedule async cleanup on a short delay so we don't block GUI thread
        self._thumb_worker_running = False
        self._frame_worker_running = False

    def _thumb_worker(self):
        if self.stop_event.is_set():
            self._thumb_worker_running = False
            return

        while not self.thumb_queue.empty():
            try:
                item = self.thumb_queue.get_nowait()
                self.thumb_pool.submit(self._process_thumb, item)
            except queue.Empty:
                break
            except Exception as e:
                print("Thumbnail pool submit error:", e)
                break

        self.thumb_after_id = self.gui.after(100, self._thumb_worker)

    def _process_thumb(self, item):
        def update_left():
            self.left -= 1
            gui.frame_gen_queue_var.set(f"Thumbs left: {self.left}")
        fm = self.fileManager
        gui = self.fileManager.gui
        obj = item
        try:
            if self.stop_event.is_set():
                return
            self.gen_thumb(obj, size=gui.thumbnailsize, cache_dir=fm.data_dir)
        except Exception as e:
            print("Error encountered in Thumbmanager:", e)
        finally:
            self.thumb_queue.task_done()
            gui.after(0, update_left)

    def _frame_worker(self):
        if self.stop_event.is_set():
            self._frame_worker_running = False
            return
        while not self.frame_queue.empty() and self.thumb_queue.unfinished_tasks == 0:
            try:
                item = self.frame_queue.get_nowait()
                self.frame_pool.submit(self._process_frame, item)
            except queue.Empty:
                break
            except Exception as e:
                print("Frame pool submit error:", e)
                break
        self.frame_after_id = self.gui.after(100, self._frame_worker)

    def _process_frame(self, item):
        def update_left(left_value):
            self.left_f -= 1
            gui.frame_gen_queue_var.set(f"Frames left: {self.left_f}")
        fm = self.fileManager
        gui = self.gui

        obj = item
        if self.stop_event.is_set():
            try:
                self.frame_queue.task_done()
            except Exception:
                pass
            return

        with self._cf_cond:
            # loop until slot available or stop event or shutdown
            while fm.concurrent_frames >= fm.max_concurrent_frames and not self.stop_event.is_set() \
                and not self.stop_event.is_set():
                self._cf_cond.wait(timeout=0.5)

            if self.stop_event.is_set():
                try:
                    self.frame_queue.task_done()
                except Exception:
                    pass
                return

        try:
            self.gen_frames(obj)
        except Exception as e:
            print("Frame generation error:", e)
        finally:
            try:
                self.frame_queue.task_done()
            except Exception:
                pass

            with self._left_lock:
                self.left_f = max(0, self.left_f - 1)
                left_value = self.left_f
           
            gui.after(0, lambda v=left_value: gui.frame_gen_queue_var.set(f"Frames left: {v}"))

    def flush_all(self):
        self.stop_event.set()

        if self.thumb_after_id:
            self.gui.after_cancel(self.thumb_after_id)
        if self.frame_after_id:
            self.gui.after_cancel(self.frame_after_id)
        self._thumb_worker_running = False
        self._frame_worker_running = False

        for q in (self.thumb_queue, self.frame_queue):
            with q.mutex:
                q.queue.clear()
        
    def generate(self, imgfiles):
        self.stop_event.clear()
        for x in imgfiles:
            if not x.thumb:
                self.left += 1
                self.thumb_queue.put(x)
            else:
                pass

        for x in imgfiles:
            if x.ext in self.anim_ext and not x.frames:
                self.left_f += 1
                self.frame_queue.put(x)
                #gui.imagegrid.change_square_color(x, "purple")
        self.start_background_worker()

    def gen_name(self, obj):
        if self.fileManager.thumbs.stop_event.is_set() or not (obj.frame or obj.destframe): return
        trunc = obj.truncated_filename or self.truncator.truncate(obj.name)
        obj.truncated_filename = trunc
        if obj.frame: self.gui.imagegrid.canvas.itemconfig(obj.frame.ids["label"], text=obj.truncated_filename)   
        if obj.destframe: self.gui.folder_explorer.destw.canvas.itemconfig(obj.destframe.ids["label"], text=obj.truncated_filename)         

    def gen_thumb(self, obj, size, cache_dir, user="default", mode="as_is"): # session just calls this for displayedlist
        gui = self.fileManager.gui
        THUMB_FORMAT = self.fileManager.THUMB_FORMAT
        def load_thumb(thumb):
            "Loads thumb to canvas"
            def run(thumb):
                if self.stop_event.is_set(): return
                self.gen_name(obj)
                instances = [f for f in (obj.frame, obj.destframe) if f]
                if instances: obj.thumb = thumb
                for f in instances:
                    f.change_image(obj.thumb)

            gui.after_idle(run, thumb)

        # first we check if we need to stop, and make sure id is generated.
        if self.stop_event.is_set(): return
        if user=="default" and not (obj.frame or obj.destframe): return
        elif user == "mobilenet":
            if obj.embed is not None and obj.color_embed is not None: return # no mobilenet or color inferring needed
        else:
            if not obj.id: obj.gen_id()

        if user == "default" and obj.thumb:
            load_thumb(obj.thumb)
            return
            
        pil_img = None
        if cache_dir:
            thumbnail_path = os.path.join(cache_dir, f"{obj.id}{THUMB_FORMAT}")
        if cache_dir and os.path.exists(thumbnail_path): # default and train will have cache_dir
            try:
                if user != "default": return
                with Image.open(thumbnail_path) as pil_img:
                    obj.thumbnail = thumbnail_path
                    thumb = ImageTk.PhotoImage(pil_img)
                    load_thumb(thumb)
                return
            except Exception as e:
                print(f"Pillows couldn't load thumbnail from cache: {obj.name} : Error: {e}.")

        # if no found, we should generate it.
        vips_used = False
        if obj.ext in self.video_ext: #Webm, mp4
            try:
                from imageio import get_reader
            except Exception as e:
                get_reader = None
                print(f"[Warning] imageio.get_reader unavailable: {e}")
            try:
                reader = None
                if get_reader is None:
                    raise RuntimeError("imageio.get_reader unavailable")
                reader = get_reader(obj.path)
                pil_img = Image.fromarray(reader.get_data(0))
            except Exception as e:
                print(f"Couldn't create thumbnail for video: {obj.name} : Error: {e}")
            finally: 
                if reader: reader.close()
        else:
            if mode == "as_is":
                try:
                    vips_img = pyvips.Image.thumbnail(obj.path, size)
                    buffer = vips_img.write_to_memory()
                    pformat = str(vips_img.interpretation).lower()
                    if pformat == "srgb":
                        if vips_img.bands == 3: pformat = "RGB"
                        elif vips_img.bands == 4: pformat = "RGBA"
                    elif pformat == "b-w": pformat = "L"
                    elif pformat == "rgb16": pformat = "I;16"
                    elif pformat == "grey16": pformat = "I;16"
                    pil_img = Image.frombytes(pformat, (vips_img.width, vips_img.height), buffer, "raw")
                    vips_used = True
                except Exception as e: # Pillow fallback
                    print(f"Pyvips couldn't create thumbnail: {obj.name} : Error: {e}.")
            if not vips_used:
                try:
                    with Image.open(obj.path) as pil_img:
                        pil_img = pil_img.copy()
                except Exception as e:
                    print(f"Pillows couldn't create thumbnail, either: {obj.name} : Error: {e}")

        if not pil_img: 
            return

        # now we have a pil_img we should convert it if needed
        if user == "default":
            if pil_img.mode not in ("RGBA", "RGB"): # Train, infer and mobilenet want rgb
                pil_img = pil_img.convert("RGBA")
        if pil_img.mode != ("RGB"):
            pil_img = pil_img.convert("RGB")

        # resize according to mode
        if mode == "as_is" and not vips_used: 
            pil_img.thumbnail((size, size))
        elif mode == "stretch": 
            pil_img = pil_img.resize((size, size))
        elif mode == "letterbox":
            pil_img.thumbnail((size, size))
            w, h = pil_img.size
            new_im = Image.new("RGB", (size, size), (114, 114, 114))
            left = (size - w) // 2
            top = (size - h) // 2
            new_im.paste(pil_img, (left, top))
            pil_img = new_im
        elif mode == "center_crop":
            w, h = pil_img.size
            side = min(w, h)
            left = (w - side) // 2
            top = (h - side) // 2
            pil_img = pil_img.crop((left, top, left + side, top + side))
            pil_img = pil_img.resize((size, size), Image.BILINEAR)

        # save it to cache if we can
        if cache_dir and pil_img: # default and train
            pil_img.save(thumbnail_path, format=THUMB_FORMAT[1:])
            if user == "default": # for default, save path to imgfile and gen imgtk for it.
                obj.thumbnail = thumbnail_path
                thumb = ImageTk.PhotoImage(pil_img)
                load_thumb(thumb)

        if user == "classify":
            return pil_img, obj # for classify
        elif user == "mobilenet":
            from numpy import array, uint8
            return array(pil_img, dtype=uint8), obj # for mobilenet
                
    def gen_frames(self, obj):
        """
        Generate frames and place inside imagefile. Sets lazy_loading to True until done or exits otherwise.
        If told to exit, clears everything it created, and sets lazy_loading to False.
        Expects frames to be empty.

        GIF, WEBP:
            Uses pyvips -> numpy -> PIL -> ImageTk
        MP4, WEBM:
            Uses mediainfo -> av -> (PIL) -> ImageTk: av does the PIL transformation.
        """
        
        gui = self.gui
        size = gui.thumbnailsize
        animate = self.fileManager.animate
        path = obj.path
        if self.stop_event.is_set(): 
            return
        
        def gui_enable_animation(o=obj):
            animate.add_animation(o)
            #self.gui.imagegrid.change_square_color(obj, "orange")
        if obj.ext in self.video_ext:
            from pymediainfo import MediaInfo
            def pick_sampling_rate(duration: float, native_fps: float,min_fps: float = 12.0, max_frames: int = 500, mode: str = "stretch"):
                """
                Calculates desired fps and framecount for the extractors.
                Allows us to crop the video to our desired amount of frames, and allows us to set minimum fps for frametimes.
                pre:
                        float:  duration
                        float:  native_fps
                        float:  min_fps     > 0.0
                        int:    max_frames  > 0
                        str:    mode        = stretch/limit
                """

                if duration == 0.0: 
                    return native_fps if native_fps != 0.0 else min_fps
                cap_rate = max_frames / duration # highest fps if we dont crop duration, but respect max_frames.

                if mode == "stretch": # respect only max_frames.
                    if native_fps * duration <= max_frames:
                        sampling_fps = native_fps # native fps is used if the frames would be under max_frames.
                    else:
                        sampling_fps = cap_rate

                elif mode == "limit": # respect min_fps.
                    if native_fps * duration <= max_frames:
                        sampling_fps = native_fps
                    elif cap_rate >= min_fps: # prefers higher fps before min_fps
                        sampling_fps = cap_rate
                    else:
                        sampling_fps = min_fps # respects min_fps, but will exceed max_frames

                # never exceed the video's own frame-rate
                sampling_fps = min(sampling_fps, native_fps)
                
                frame_count = min(max_frames, round(duration * sampling_fps))

                return sampling_fps, frame_count         
            def get_fps_and_duration(path: str):
                mi = MediaInfo.parse(path)
                vt = next((t for t in mi.tracks if t.track_type=="Video"), None)
                gt = next((t for t in mi.tracks if t.track_type=="General"), None)
                if not vt or not gt:
                    raise RuntimeError("Missing tracks")
                # fps
                if vt.frame_rate_num and vt.frame_rate_den:
                    fps = float(vt.frame_rate_num) / float(vt.frame_rate_den)
                else:
                    fps = float(vt.frame_rate or 0) or 24.0
                # duration in seconds
                duration = float(gt.duration or 0) / 1000.0
                return fps, duration                        
            def extract_with_pyav(path: str, timestamps: list, frametime_ms: int):
                """
                Return a list of n randomly-sampled PIL.Image frames from path using PyAV.
                """
                import av
                # First, probe duration
                with av.open(path) as container:
                    video_stream = container.streams.video[0]
                    time_base = video_stream.time_base
                    
                    for t in timestamps:
                        if self.stop_event.is_set() or not (obj.frame or obj.destframe):
                            gui.after_idle(obj.clear_frames)
                            #self.gui.imagegrid.change_square_color(obj, "red")
                            break
                        container.seek(int(t / time_base), any_frame=False, backward=True, stream=video_stream)
                        for packet in container.demux(video_stream):
                            for frame in packet.decode():
                                if frame.pts * time_base >= t:
                                    img = frame.to_image()
                                    img.thumbnail((size, size))
                                    obj.frames.append((ImageTk.PhotoImage(img), frametime_ms))
                                    if len(obj.frames) == 2:
                                        self.gui.after_idle(gui_enable_animation)
                                    break
                            else:
                                continue
                            break

            try:
                fps, duration = get_fps_and_duration(path)
                sampling_fps, n = pick_sampling_rate(duration=duration, native_fps=fps, min_fps=12, max_frames=100, mode="limit")
                frametime_ms = int(round(1000.0 / sampling_fps))
                timestamps = [(i / sampling_fps) for i in range(n)]
            
                extract_with_pyav(path, timestamps, frametime_ms)
            except Exception as e:
                print("error in gen frames (av)", e)

        elif obj.ext in self.anim_ext:
            with Image.open(obj.path, "r") as img:
                i = 0
                while True:
                    if self.stop_event.is_set() or not (obj.frame or obj.destframe):
                        gui.after_idle(obj.clear_frames)
                        #self.gui.imagegrid.change_square_color(obj, "red")
                        return
                    try:
                        
                        img.seek(i)
                        duration = img.info.get('duration', 100) or 100
                        
                        frame = img.copy().convert("RGBA")
                        frame.thumbnail((gui.thumbnailsize, gui.thumbnailsize))
                        obj.frames.append((ImageTk.PhotoImage(frame), duration))
                        i += 1

                        if len(obj.frames) == 2:
                            self.gui.after_idle(gui_enable_animation)
                    except EOFError:
                        break
                    except Exception as e:
                        print("gen fraems error:", e)
                        break

        if len(obj.frames) <= 1:
            gui.after_idle(obj.clear_frames)
            #self.gui.imagegrid.change_square_color(obj, obj.color)
        obj.change_color_flag = True

class Animate: # this can stay here. it must touch both gridviewers so..
    def __init__(self, fileManager):
        self.gui = fileManager.gui
        self.imagegrid = fileManager.imagegrid

        self.running = {}  # obj -> after_id (for cancellation)

    def add_animation(self, obj):
        """Start per-object animation respecting frame delays."""
        if obj in self.running: return

        obj.index = 0
        self._step(obj)

    def _step(self, obj):
        instances = [f for f in (obj.frame, obj.destframe) if f]

        if not instances or not obj.frames:
            self.stop(obj.id)
            return
        
        # frame also has ref to the canvas! or it has a ref to function to change image.

        frame_img = obj.frames[obj.index][0]
        for f in instances:
            try:
                f.change_image(frame_img)
            except Exception as e:
                print(e)

        obj.index = (obj.index + 1) % len(obj.frames)
        delay = obj.frames[obj.index][1] or 100

        after_id = self.gui.after(delay, self._step, obj)
        self.running[obj.id] = after_id

    def stop(self, id1):
        after_id = self.running.pop(id1, None)
        if after_id: self.gui.after_cancel(after_id)

class Predictions:
    def __init__(self, fileManager):
        self.fileManager = fileManager
        self.gui = fileManager.gui
        self.train_thread = None

    def select_model(self):
        from tkinter import filedialog as tkFileDialog
        self.gui.model_path = tkFileDialog.askopenfilename(defaultextension=".pt", filetypes=(("Model File", "*.pt"),),initialdir=self.fileManager.model_dir, title="Select a model to use.")

    def open_category_manager(self):
        def on_close():
            self.gui.categories = [path for path, state in self.app.folder_states.items() if state == "category"]
            self.gui.excludes = [path for path, state in self.app.folder_states.items() if state == "exclude"]
            self.app.destroy()
        from Advanced_sorting import FolderTreeApp
        dest_root = self.destination_entry_field.get()
        self.app = FolderTreeApp(dest_root, self.gui.categories, self.gui.excludes, self.manual_training) 
        self.app.protocol("WM_DELETE_WINDOW", on_close)
                 
    def get_folder_contents_with_labels(self, destinations, excludes=[]):
        categories = [os.path.abspath(c) for c in destinations]
        excludes = set(os.path.abspath(e) for e in excludes)
        data = {}
        for category_path in categories:
            label = os.path.basename(category_path)
            label_list = data.get(label, [])
            data[label] = label_list
            print(f"[Category] {category_path}")

            for root, dirs, files in os.walk(category_path):
                abs_root = os.path.abspath(root)

                # Prune dirs list to exclude excluded or category folders, so os.walk won't go into them
                pruned_dirs = []
                for d in dirs:
                    d_abs = os.path.abspath(os.path.join(root, d))

                    if any(d_abs == ex or d_abs.startswith(ex + os.sep) for ex in excludes):
                        pass
                    elif any(d_abs == cat for cat in categories):
                        pass
                    else:
                        pruned_dirs.append(d)
                dirs[:] = pruned_dirs
                
                print(f"  Subfolder: {abs_root}")

                for file in files:
                    if file.lower().endswith(("png", "gif", "jpg", "jpeg", "bmp", "pcx", "tiff", "webp", "psd", "jfif", "mp4", "mkv", "m4v", "mov", "webm")):
                        data[label].append((os.path.join(root, file)))
        return data
         
    def manual_training(self, name="latest_model"):
        def train():   
            self.gui.categories = [path for path, state in self.app.folder_states.items() if state == "category"]
            self.gui.excludes = [path for path, state in self.app.folder_states.items() if state == "exclude"]
            names_2_path = {os.path.basename(x): x for x in self.gui.categories}
            with open(os.path.join(self.fileManager.model_dir, f"{name}_paths.json"), "w") as f:
                json_dict = {}
                json_dict["names_2_path"] = names_2_path
                json.dump(json_dict, f, indent=4)

            print("Category folders:")
            for path in self.gui.categories:
                print("  ", path)

            print("Excluded folders:")
            for path in self.excludes:
                print("  ", path)

            label_path_dict = self.get_folder_contents_with_labels(self.gui.categories, self.gui.excludes)

            self.gui.train_status_var.set("Building dataset...")
            from Advanced_sorting import Dataset_gen
            Data = Dataset_gen(self.fileManager.train_dir, label_path_dict, self.gui.prediction_thumbsize, self.fileManager)       
            path_hash_lookup = Data.gen_thumbs()
            Data.split(0.9)
            
            self.gui.train_status_var.set("Starting model...")
            
            try:
                # Import and run directly - no subprocess needed
                from train_model import main as train_main
                
                train_main(
                    data=self.fileManager.train_dir,
                    epochs=100,
                    name=name,
                    model="yolo11s-cls.pt",
                    output_dir=self.fileManager.model_dir
                )
            except Exception as e:
                self.gui.train_status_var.set(f"Training error: {e}")
                print(f"Training error: {e}")
                return
            
            self.gui.model_path = os.path.join(self.fileManager.model_dir, f"{name}.pt")
            
        if self.train_thread and self.train_thread.is_alive():
            print("Already running.")
            return
        self.train_thread = threading.Thread(target=train, name="Manual-training", daemon=True)
        self.train_thread.start()
    
    def automatic_training(self):
        "Generate all files from destinations. Assign as categories. Need self.labels... Inferring size and pred_dir location."
        def train():
            self.gui.train_status_var.set("Labelling dataset...")

            label_path_dict = self.get_folder_contents_with_labels([folder_path for _, folder_path, _, _, _ in self.gui.buttons])
            
            self.gui.train_status_var.set("Building dataset...")
            from Advanced_sorting import Dataset_gen
            Data = Dataset_gen(self.fileManager.train_dir, label_path_dict, self.gui.prediction_thumbsize, self.fileManager)       
            path_hash_lookup = Data.gen_thumbs()
            Data.split(0.9)
            
            self.gui.train_status_var.set("Starting model...")
            names_2_path = {os.path.basename(x[1]): x[1] for x in self.gui.buttons}

            with open(os.path.join(self.fileManager.model_dir, "latest_model_paths.json"), "w") as f:
                json_dict = {}
                json_dict["names_2_path"] = names_2_path
                json.dump(json_dict, f, indent=4)

            try:
                # Import and run directly - no subprocess needed
                from train_model import main as train_main
                
                train_main(
                    data=self.fileManager.train_dir,
                    epochs=100,
                    name="latest_model",
                    model="yolo11s-cls.pt",
                    output_dir=self.fileManager.model_dir
                )
                
            except Exception as e:
                self.gui.train_status_var.set(f"Training error: {e}")
                print(f"Training error: {e}")
                return

            self.model_path = os.path.join(self.fileManager.model_dir, f"latest_model.pt")
            self.gui.train_status_var.set("Model Ready.")
        
        if self.train_thread and self.train_thread.is_alive():
            print("Already running.")
            return
        if self.gui.imagegrid.image_items:
            self.train_thread = threading.Thread(target=train, name="Auto-training", daemon=True)
            self.train_thread.start()
        else:
            print("You must start a new session before auto-training to generate the destinations.")
    
    def model_infer(self, model=None, imagefiles=[]):
        if not imagefiles:
            return
        self.gui.train_status_var.set("Loading model...")
        from Advanced_sorting import Model_inferer
        model_inferer = Model_inferer(self.fileManager, model, self.gui.prediction_thumbsize)
        for x in imagefiles:
            if x.id == None:
                x.gen_id()
        lookup = {x.id: x for x in imagefiles}
        self.gui.train_status_var.set("Sorting...")

        thread = threading.Thread(target=model_inferer.infer, args=(imagefiles, lookup), daemon=True)
        thread.start()

        self.last_model = model
        
class Timer:
    def __init__(self):
        self.creation_time = 0
    def start(self):
        self.creation_time = time.perf_counter()
    def stop(self):
        current_time = time.perf_counter()
        elapsed_time = current_time - self.creation_time
        return f"{elapsed_time:.3f} s"

if __name__ == '__main__':
    mp.freeze_support()
    ctypes.windll.shcore.SetProcessDpiAwareness(1)
    
    # Only set start method in the main process
    mp.set_start_method('spawn', force=True)

    # 3. Only start the app here
    mainclass = SortImages()
    
